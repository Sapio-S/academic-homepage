---
title:          "RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation"
date:           2025-09-16 00:01:00 +0800
selected:       false
pub:            "USENIX Symposium on Operating Systems Design and Implementation (OSDI)"
pub_pre:        "Submitted to "
pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2026"
semantic_scholar_id: 44c875bd75dfeca46096b44bd9b7ef1a53bcb28c  # use this to retrieve citation count
abstract: >-
  We present RLinf, a high-performance RL training system. To maximize flexibility and efficiency, RLinf is built atop a novel RL system design paradigm called macro-to-micro flow transformation (M2Flow), which automatically breaks down high-level RL workflows and recomposes them into optimized execution flows.
cover:          /assets/images/publications/osdi25.png
authors:
  - Chao Yu
  - Yuanqing Wang
  - Zhen Guo
  - Hao Lin
  - Si Xu
  - Hongzhi Zang
  - Quanlu Zhang
  - Yongji Wu
  - Chunyang Zhu
  - Junhao Hu
  - Zixiao Huang
  - Mingjie Wei
  - Yuqing Xie
  - Ke Yang
  - Bo Dai
  - Zhexuan Xu
  - Xiangyuan Wang
  - Xu Fu
  - Zhihao Liu
  - Kang Chen
  - Weilin Liu
  - Gang Liu
  - Boxun Li
  - Jianlei Yang
  - Zhi Yang
  - Guohao Dai
  - Yu Wang
links:
  Paper: https://arxiv.org/pdf/2509.15965
  Code: 
  Doc: 
---
