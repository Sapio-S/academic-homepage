---
title:          "RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"
date:           2025-10-1 00:01:00 +0800
selected:       false
pub:            "arxiv"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"
semantic_scholar_id: b9c05ac2d0488ea1924714ba6c19a803c4ff099f  # use this to retrieve citation count
abstract: >-
  We introduce RLinf-VLA, a unified and efficient framework for scalable RL training of VLA models. The system adopts a highly flexible resource allocation design that addresses the challenge of integrating rendering, training, and inference in RL+VLA training.

cover:          /assets/images/publications/arxiv25.png
authors:
  - Hongzhi Zang
  - Mingjie Wei
  - Si Xu
  - Yongji Wu
  - Zhen Guo
  - Yuanqing Wang
  - Hao Lin
  - Liangzhi Shi
  - Yuqing Xie
  - Zhexuan Xu
  - Zhihao Liu
  - Kang Chen
  - Wenhao Tang
  - Quanlu Zhang
  - Weinan Zhang
  - Chao Yu
  - Yu Wang
links:
  Paper: https://arxiv.org/pdf/2510.06710
---
