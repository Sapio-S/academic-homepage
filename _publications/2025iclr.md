---
title:          "Automatic Reward Shaping from Multi-Objective Human Heuristics"
date:           2025-09-12 00:01:00 +0800
selected:       true
pub:            "NeurIPS 2025 Workshop: Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists"
# pub_date:       "2025"
pub_pre2:        "Submitted to "
pub2: "International Conference on Learning Representations (ICLR)"
pub_post2:       'Under review.'
pub_date2:       "2026."
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'

# semantic_scholar_id: 4b3c264b4a7f8117d3e4c7a576c29e129591e497  # use this to retrieve citation count
abstract: >-
  We propose Multi-Objective Reward Shaping with Exploration, a general framework that automatically combines multiple human-designed heuristic rewards into a unified reward function. MORSE formulates the shaping process as a bi-level optimization problem: the inner loop trains a policy to maximize the current shaped reward, while the outer loop updates the reward function to optimize task performance. To encourage exploration in the reward space, MORSE introduces stochasticity into the outer-loop optimization.

cover:          /assets/images/publications/iclr25.png
authors:
  - Yuqing Xie
  - Jiayu Chen
  - Chao Yu
  - Yu Wang
links:
  Paper: https://openreview.net/pdf?id=eVxvd3jU25
---
